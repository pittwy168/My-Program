"""
Value Iteration
"""

def v(matrix, reward, terminal, lamma=0.7, prob=0.7):
    n = len(matrix)
    m = len(matrix[0])
    new_matrix=[[0. for i in range(m)] for j in range(n)]
    for i in range(n):
        for j in range(m):
            if [i,j] in terminal:
                new_matrix[i][j] = reward[i][j]
                continue
            v=float('-Inf')
            for x in [[0,1],[0,-1],[-1,0],[1,0]]:
                a1,b1 = i+x[0],j+x[1]
                a2,b2 = i-x[0],j-x[1]
                if a1<0: a1=0
                if a2<0: a2=0
                if a1>n-1: a1=n-1
                if a2>n-1: a2=n-1
                if b1<0: b1=0
                if b2<0: b2=0
                if b1>m-1: b1=m-1
                if b2>m-1: b2=m-1
                v = max(v, lamma*(prob*matrix[a1][b1]+(1.0-prob)*matrix[a2][b2])+reward[i][j])
            new_matrix[i][j] = v
    return new_matrix


reward = [[-100.,10.,10. ,100.],[-5.,10.,-5.,10.],[-5.,-30.,10.,-30.]]
terminal =[[0,0],[0,3]]
tt=new_matrix=[[0. for i in range(4)] for j in range(3)]

matrix1 = v(tt, reward, terminal, lamma=0.7, prob=0.7)
matrix2 = v(matrix1, reward, terminal, lamma=0.7, prob=0.7)
matrix3 = v(matrix2, reward, terminal, lamma=0.7, prob=0.7)
print matrix1
print matrix2
print matrix3

"""
Original Policy Iteration
"""
import numpy as np
def policy(old_policy, reward, terminal, lamma=0.7, prob=0.7):
    n = len(old_policy)
    m = len(old_policy[0])
    coeff=[[0. for i in range(n*m)] for j in range(n*m)]
    const=[0. for i in range(n*m) ]

    for i in range(n):
        for j in range(m):
            if [i,j] in terminal:
                coeff[m*i+j][m*i+j] = 1.0
                const[m*i+j] = reward[i][j]
                continue
            a1,a2,b1,b2=0,0,0,0

            if old_policy[i][j]=='n':
                a1,b1 = i-1,j
                a2,b2 = i+1,j
            elif old_policy[i][j]=='s':
                a1,b1 = i+1,j
                a2,b2 = i-1,j
            elif old_policy[i][j]=='e':
                a1,b1 = i,j+1
                a2,b2 = i,j-1
            elif old_policy[i][j]=='w':
                a1,b1 = i,j-1
                a2,b2 = i,j+1
            if a1<0: a1=0
            if a2<0: a2=0
            if a1>n-1: a1=n-1
            if a2>n-1: a2=n-1
            if b1<0: b1=0
            if b2<0: b2=0
            if b1>m-1: b1=m-1
            if b2>m-1: b2=m-1
            coeff[m*i+j][m*a1+b1] += lamma*prob
            coeff[m*i+j][m*a2+b2] += lamma*(1-prob)
            coeff[m*i+j][m*i+j] += -1.0
            const[m*i+j] = -1.0*reward[i][j]
    return np.linalg.solve(np.array(coeff), np.array(const))

reward = [[-100.,10.,10. ,100.],[-5.,10.,-5.,10.],[-5.,-30.,10.,-30.]]
matrix1 = [[-100.,10.,10. ,100.],[-5.,10.,-5.,10.],[-5.,-30.,10.,-30.]]
terminal =[[0,0],[0,3]]

tt1=[['n' for i in range(4)] for j in range(3)]
tt2= [['n','e','e','n'],['e','n','e','n'],['e','e','n','n']]
tt3= [['n','e','e','n'],['e','e','n','n'],['n','e','n','n']]
print policy(tt1, reward, terminal, lamma=0.7, prob=0.7)
print policy(tt2, reward, terminal, lamma=0.7, prob=0.7)
print policy(tt3, reward, terminal, lamma=0.7, prob=0.7)

"""
Modified Policy Iteration K=1, N=3
"""
def mpolicy(old_policy, matrix, reward, terminal, lamma=0.7, prob=0.7):
    n = len(old_policy)
    m = len(old_policy[0])
    new_matrix=[[0. for i in range(m)] for j in range(n)]

    for i in range(n):
        for j in range(m):
            if [i,j] in terminal:
                new_matrix[i][j] = reward[i][j]
                continue
            a1,a2,b1,b2=0,0,0,0

            if old_policy[i][j]=='n':
                a1,b1 = i-1,j
                a2,b2 = i+1,j
            elif old_policy[i][j]=='s':
                a1,b1 = i+1,j
                a2,b2 = i-1,j
            elif old_policy[i][j]=='e':
                a1,b1 = i,j+1
                a2,b2 = i,j-1
            elif old_policy[i][j]=='w':
                a1,b1 = i,j-1
                a2,b2 = i,j+1
            if a1<0: a1=0
            if a2<0: a2=0
            if a1>n-1: a1=n-1
            if a2>n-1: a2=n-1
            if b1<0: b1=0
            if b2<0: b2=0
            if b1>m-1: b1=m-1
            if b2>m-1: b2=m-1
            new_matrix[i][j] = lamma*(prob*matrix[a1][b1]+(1.0-prob)*matrix[a2][b2])+reward[i][j]
    return new_matrix

reward = [[-100.,10.,10. ,100.],[-5.,10.,-5.,10.],[-5.,-30.,10.,-30.]]
value = [[-100.,10.,10. ,100.],[-5.,10.,-5.,10.],[-5.,-30.,10.,-30.]]
matrix1 = [[-100.,10.,10. ,100.],[-5.,10.,-5.,10.],[-5.,-30.,10.,-30.]]
terminal =[[0,0],[0,3]]
tt=[['n' for i in range(4)] for j in range(3)]
tt2= [['n','e','e','n'],['e','n','e','n'],['e','e','n','n']]
tt3= [['n','e','e','n'],['e','e','n','n'],['n','e','n','n']]
matrix2 = mpolicy(tt, matrix1, reward, terminal, lamma=0.7, prob=0.7)
matrix3 = mpolicy(tt2, matrix2, reward, terminal, lamma=0.7, prob=0.7)
print mpolicy(tt3, matrix3, reward, terminal, lamma=0.7, prob=0.7)


